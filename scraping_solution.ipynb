{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yotam-biu/tutorial6/blob/main/scraping_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "681d7c9e",
      "metadata": {
        "id": "681d7c9e"
      },
      "source": [
        "# Read `HTML`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependency"
      ],
      "metadata": {
        "id": "QnSQAvVkNRhk"
      },
      "id": "QnSQAvVkNRhk"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import the necessary libraries**\n",
        "* Begin by importing the requests library to send HTTP requests.\n",
        "* Then, import BeautifulSoup from the bs4 module to parse HTML content.\n",
        "* Finally, import the pandas library as pd to work with tabular data."
      ],
      "metadata": {
        "id": "a2giNT4dS0QB"
      },
      "id": "a2giNT4dS0QB"
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "c0dqLGFcNQ5h"
      },
      "id": "c0dqLGFcNQ5h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read as normal html file"
      ],
      "metadata": {
        "id": "zYR3sZ48M6hi"
      },
      "id": "zYR3sZ48M6hi"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**requests**\n",
        "\n",
        "1. Get the URL address\n",
        "To begin, you need to define or obtain the URL from which you want to fetch content. Use this [link](https://people.mbi.ucla.edu/sumchan/codon_table.html) to get to the website.\n",
        "\n",
        "\n",
        "2. Use `requests.get()` function to make a GET request\n",
        "The `requests.get(url)` function requires the URL as its input argument. This is the URL you want to retrieve data from. In our case, we are passing the URL variable defined in the first step.\n",
        "The requests.get() function sends an HTTP GET request to the specified URL and returns a response object. The response object contains information about the request, including the content of the URL.\n",
        "\n",
        "3. Print the content of the URL using the `.content` attribute of the response GET object."
      ],
      "metadata": {
        "id": "NHs_YNdyOA3F"
      },
      "id": "NHs_YNdyOA3F"
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://people.mbi.ucla.edu/sumchan/codon_table.html\"\n",
        "url_content = requests.get(url).content\n",
        "# url_content"
      ],
      "metadata": {
        "id": "VPYUiU8JM-RL"
      },
      "id": "VPYUiU8JM-RL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BeautifulSoup**\n",
        "\n",
        "1. Use BeautifulSoup to parse the HTML content you received from the response.content. This is done by creating a BeautifulSoup object, passing the content as the first argument and the parser type ('html.parser') as the second argument.```python soup = BeautifulSoup(url_content, 'html.parser')```\n",
        "\n",
        "2. How do you extract the first <table> element from the parsed content?\n",
        "\n",
        "3. From the table you got in the last step, how do you extract all the <tr> (table row) elements?\n",
        "\n",
        "4. For the rows you got in the last step, how do you access the first row of the table? After printing it, what problem do you see with the first row?"
      ],
      "metadata": {
        "id": "qzTqLnlEQTGq"
      },
      "id": "qzTqLnlEQTGq"
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(url_content, 'html.parser')\n",
        "\n",
        "table = soup.find('table')\n",
        "rows = soup.find_all('tr')\n",
        "rows[0]"
      ],
      "metadata": {
        "id": "jyn2rLPLPTf5"
      },
      "id": "jyn2rLPLPTf5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read with the forgiving `html5lib` parser"
      ],
      "metadata": {
        "id": "1TQz-vILM-kh"
      },
      "id": "1TQz-vILM-kh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use BeautifulSoup to parse the HTML content with the 'html5lib' parser (which is more tolerant than 'html.parser'), create a BeautifulSoup object by passing the content as the first argument and the parser type ('html5lib') as the second argument.\n",
        "The only change here is the use of 'html5lib' instead of 'html.parser'. The html5lib parser is known for being more forgiving and better at handling malformed HTML."
      ],
      "metadata": {
        "id": "84E3IOCETTuX"
      },
      "id": "84E3IOCETTuX"
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(url_content, 'html5lib')\n",
        "table = soup.find('table')\n",
        "\n",
        "rows = table.find_all('tr')\n",
        "rows[0]\n"
      ],
      "metadata": {
        "id": "APLLZFTKBbsr"
      },
      "id": "APLLZFTKBbsr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract the data cell"
      ],
      "metadata": {
        "id": "2o1nkycJTpe5"
      },
      "id": "2o1nkycJTpe5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understand the Row Structure**\n",
        "\n",
        "1. Write code to inspect the contents of the first row (rows[0]) and the second row (rows[1]) to determine the structure of the table. For each row:\n",
        "\n",
        "  * Start by extracting the individual cells in the row using the `.find_all('td')` method.\n",
        "  * Create an empty list to store the text content of each cell.\n",
        "  * Loop through the extracted cells and append their `.text` content to the list.\n",
        "\n",
        "2. Notice how the first row behaves differently compared to subsequent rows. What are the differences?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "38lpkIJs9Nm8"
      },
      "id": "38lpkIJs9Nm8"
    },
    {
      "cell_type": "code",
      "source": [
        "cells = rows[0].find_all('td')\n",
        "cells_data = []\n",
        "for cell in cells:\n",
        "    cells_data.append(cell.text)\n",
        "cells_data"
      ],
      "metadata": {
        "id": "e48P96qaPuXy"
      },
      "id": "e48P96qaPuXy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cells = rows[0].find_all('td')\n",
        "cells_data = []\n",
        "for cell in cells:\n",
        "    cells_data.append(cell.text)\n",
        "cells_data"
      ],
      "metadata": {
        "id": "rMuQC0rK-sF5"
      },
      "id": "rMuQC0rK-sF5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a Dictionary"
      ],
      "metadata": {
        "id": "k-eKNXgv_SXS"
      },
      "id": "k-eKNXgv_SXS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your objective is to create a dictionary that maps data from the first column (key) to the fourth column (value) of a table.  Skip rows that don't have enough data.  \n",
        "\n",
        "1. Initialize a Dictionary. Start by creating an empty dictionary where the keys and values will be stored.  \n",
        "\n",
        "2. Loop Through Rows. Iterate through all the rows of the table, starting from the second row (skip the header row).  \n",
        "\n",
        "3. Check for Incomplete Rows. For each row, check if it has at least four cells. If a row has fewer than four cells, skip it and move to the next row.  \n",
        "\n",
        "4. Extract Key and Value. For rows with enough cells:  \n",
        "  - Take the text content of the first cell as the key.  \n",
        "  - Take the text content of the fourth cell as the value.  \n",
        "\n",
        "5. Add to Dictionary. Add the key-value pair to the dictionary.  \n",
        "\n",
        "6. Verify Your Work. After processing all rows, inspect the dictionary to ensure it contains the expected data.  \n",
        "\n",
        "---\n",
        "\n",
        "#### Final Questions to Reflect On:  \n",
        "1. What kind of data is being used as keys and values in the dictionary?  \n",
        "2. How does skipping incomplete rows help ensure data accuracy?  \n",
        "3. What potential issues might arise if the table format changes?  \n",
        "\n"
      ],
      "metadata": {
        "id": "LTLC6y6oAsDk"
      },
      "id": "LTLC6y6oAsDk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68c1b3c6",
      "metadata": {
        "id": "68c1b3c6"
      },
      "outputs": [],
      "source": [
        "\n",
        "codons2aa = {}\n",
        "for row in rows[1:]:\n",
        "    if len(row) < 3:\n",
        "        continue\n",
        "    cells = row.find_all('td')\n",
        "    key = cells[0].text\n",
        "    value = cells[3].text\n",
        "    codons2aa[key] = value\n",
        "\n",
        "\n",
        "\n",
        "codons2aa\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HzDdj1InAHgI"
      },
      "id": "HzDdj1InAHgI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read with pandas"
      ],
      "metadata": {
        "id": "P5_ejkVzQNrQ"
      },
      "id": "P5_ejkVzQNrQ"
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://people.mbi.ucla.edu/sumchan/codon_table.html\"  # URL or path to the HTML table.\n",
        "\n",
        "df = pd.read_html(url, header=None)[0]  # Read the first table from the HTML.\n",
        "\n",
        "df.columns = [\"Codon\", \"Full Name\", \"3-Letter Abbreviation\", \"1-Letter Abbreviation\", \"Frequency\"]  # Assign column names.\n",
        "\n",
        "df.head()  # Display the first few rows of the DataFrame."
      ],
      "metadata": {
        "id": "QGxMdFNEQPwL"
      },
      "id": "QGxMdFNEQPwL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uE4tXA6kR_eU"
      },
      "id": "uE4tXA6kR_eU",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}